@inproceedings{yinzhicao2015,
  author     = {Cao, Y Z and Yang, J F},
  title      = {Towards making systems forget with machine unlearning},
  editor     = {},
  booktitle  = {Proceedings of IEEE Symposium on Security and Privacy},
  address    = {Washington DC,USA},
  publisher  = {IEEE},
  year       = {2015},
  pages      = {463--480},
}

@inproceedings{antonio2019,
  author     = {Antonio, G and Melody, G and Gregory, V and et, al},
  title      = {Making ai forget you: Data deletion in machine learning},
  editor     = {},
  booktitle  = {Proceedings of Conference and Workshop on Neural Information Processing Systems},
  address    = {New York,NY,USA},
  publisher  = {MIT Press},
  year       = {2019},
  pages      = {3513--3526},
}

@ARTICLE{2019arXiv191203817B,
       author = {{Bourtoule}, Lucas and {Chandrasekaran}, Varun and {Choquette-Choo}, Christopher A. and {Jia}, Hengrui and {Travers}, Adelin and {Zhang}, Baiwu and {Lie}, David and {Papernot}, Nicolas},
        title = "{Machine Unlearning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
         year = 2019,
        month = dec,
          eid = {arXiv:1912.03817},
        pages = {arXiv:1912.03817},
archivePrefix = {arXiv},
       eprint = {1912.03817},
 primaryClass = {cs.CR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv191203817B},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@InProceedings{Golatkar_2020_CVPR,
  author = {Golatkar, Aditya and Achille, Alessandro and Soatto, Stefano},
  title = {Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep Networks},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2020},
  pages           = {9304-9312},
}

@InProceedings{Golatkar_2021_CVPR,
  author = {Aditya Golatkar and
               Alessandro Achille and
               Avinash Ravichandran and
               Marzia Polito and
               Stefano Soatto},
  title = {Mixed-Privacy Forgetting in Deep Networks},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {March},
  year = {2021}
}

@InProceedings{10.1007/978-3-030-01424-7_27,
author="Tan, Chuanqi
and Sun, Fuchun
and Kong, Tao
and Zhang, Wenchang
and Yang, Chao
and Liu, Chunfang",
editor="K{\r{u}}rkov{\'a}, V{\v{e}}ra
and Manolopoulos, Yannis
and Hammer, Barbara
and Iliadis, Lazaros
and Maglogiannis, Ilias",
title="A Survey on Deep Transfer Learning",
booktitle="Artificial Neural Networks and Machine Learning -- ICANN 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="270--279",
abstract="As a new classification platform, deep learning has recently received increasing attention from researchers and has been successfully applied to many domains. In some domains, like bioinformatics and robotics, it is very difficult to construct a large-scale well-annotated dataset due to the expense of data acquisition and costly annotation, which limits its development. Transfer learning relaxes the hypothesis that the training data must be independent and identically distributed (i.i.d.) with the test data, which motivates us to use transfer learning to solve the problem of insufficient training data. This survey focuses on reviewing the current researches of transfer learning by using deep neural network and its applications. We defined deep transfer learning, category and review the recent research works based on the techniques used in deep transfer learning.",
isbn="978-3-030-01424-7"
}

@INPROCEEDINGS{6639081,
  author={J. {Huang} and J. {Li} and D. {Yu} and L. {Deng} and Y. {Gong}},
  booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers}, 
  year={2013},
  volume={},
  number={},
  pages={7304-7308},
  doi={10.1109/ICASSP.2013.6639081}}

@InProceedings{Oquab_2014_CVPR,
author = {Oquab, Maxime and Bottou, Leon and Laptev, Ivan and Sivic, Josef},
title = {Learning and Transferring Mid-Level Image Representations using Convolutional Neural Networks},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2014}
}

@inproceedings{yosinski_2014_NIPS,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle={Advances in Neural Information Processing Systems 27 (NIPS '14)},
  editor = {Z. Ghahramani and M. Welling and C. Cortes and N.D. Lawrence and K.Q. Weinberger},
  publisher = {Curran Associates, Inc.},
  pages = {3320--3328},
  year={2014}
}

@article{PARISI201954,
title = {Continual lifelong learning with neural networks: A review},
journal = {Neural Networks},
volume = {113},
pages = {54-71},
year = {2019},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2019.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S0893608019300231},
author = {German I. Parisi and Ronald Kemker and Jose L. Part and Christopher Kanan and Stefan Wermter},
keywords = {Continual learning, Lifelong learning, Catastrophic forgetting, Developmental systems, Memory consolidation}
}

@ARTICLE{8107520,  
author={Z. {Li} and D. {Hoiem}},  
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},   
title={Learning without Forgetting},   
year={2018},  volume={40},  number={12},  pages={2935-2947},  doi={10.1109/TPAMI.2017.2773081}}

@article{Sarwar_2020,
   title={Incremental Learning in Deep Convolutional Neural Networks Using Partial Network Sharing},
   volume={8},
   ISSN={2169-3536},
   url={http://dx.doi.org/10.1109/ACCESS.2019.2963056},
   DOI={10.1109/access.2019.2963056},
   journal={IEEE Access},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Sarwar, Syed Shakib and Ankit, Aayush and Roy, Kaushik},
   year={2020},
   pages={4615–4628}
}

@ARTICLE{2018arXiv181205159T,
       author = {{Toneva}, Mariya and {Sordoni}, Alessandro and {Tachet des Combes}, Remi and {Trischler}, Adam and {Bengio}, Yoshua and {Gordon}, Geoffrey J.},
        title = "{An Empirical Study of Example Forgetting during Deep Neural Network Learning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2018,
        month = dec,
          eid = {arXiv:1812.05159},
        pages = {arXiv:1812.05159},
archivePrefix = {arXiv},
       eprint = {1812.05159},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv181205159T},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Hubel1998EarlyEO,
  title={Early Exploration of the Visual Cortex},
  author={D. Hubel and T. Wiesel},
  journal={Neuron},
  year={1998},
  volume={20},
  pages={401-412}
}

@article{https://doi.org/10.1113/jphysiol.1959.sp006308,
author = {Hubel, D. H. and Wiesel, T. N.},
title = {Receptive fields of single neurones in the cat's striate cortex},
journal = {The Journal of Physiology},
volume = {148},
number = {3},
pages = {574-591},
doi = {https://doi.org/10.1113/jphysiol.1959.sp006308},
url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1959.sp006308},
eprint = {https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.1959.sp006308},
year = {1959}
}

@ARTICLE{2019arXiv190906161K,
       author = {{Kubilius}, Jonas and {Schrimpf}, Martin and {Kar}, Kohitij and {Hong}, Ha and {Majaj}, Najib J. and {Rajalingham}, Rishi and {Issa}, Elias B. and {Bashivan}, Pouya and {Prescott-Roy}, Jonathan and {Schmidt}, Kailyn and {Nayebi}, Aran and {Bear}, Daniel and {Yamins}, Daniel L.~K. and {DiCarlo}, James J.},
        title = "{Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Electrical Engineering and Systems Science - Image and Video Processing, Quantitative Biology - Neurons and Cognition},
         year = 2019,
        month = sep,
          eid = {arXiv:1909.06161},
        pages = {arXiv:1909.06161},
archivePrefix = {arXiv},
       eprint = {1909.06161},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190906161K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@online{jiahui2020,
  author     = {Jia Hui and Ju Guang and Keliang (Clay) Zhu},
  title      = {数据保护系列：《加州消费者隐私法案》及其启示},
  year       = {2020},
  date       = {2020-02-27},
  urldate    = {2021-04-15},
  url        = {https://www.mondaq.com/china/privacy/898314/25968254542044525252319952101565306122982115224030280403615332773385443116927861266961229921450208542155131034},
  key        = {xiao1 yu4},
}

@book{zhouzhihua2016,
  author     = {周志华},
  title      = {机器学习},
  address    = {北京},
  publisher  = {清华大学出版社},
  year       = {2016},
  pages      = {56--60},
  key        = {zhou1 zhi4 hua2},
}

@patent{lingqiang2016,
  author     = {凌强 and 单廷佳 and 李峰},
  title      = {一种基于cnn的快速图像检索方法: 中国, CN105912611A},
  date       = {2016-08-31},
  key        = {ling2 qiang2},
}

@online{ccpa2020,
  author     = {{State of California Department of Justice}},
  title      = {California Consumer Privacy Act (CCPA)},
  year       = {2020},
  date       = {2020-08-27},
  urldate    = {2021-04-15},
  url        = {https://oag.ca.gov/privacy/ccpa},
  key        = {xiao1 yu4},
}

@online{gdpr2018,
  author     = {{Intersoft Consulting}},
  title      = {General Data Protection Regulation (GDPR)},
  year       = {2018},
  date       = {2018-05-25},
  urldate    = {2021-04-15},
  url        = {https://gdpr-info.eu/},
  key        = {xiao1 yu4},
}

@standard{gbt35273,
  author     = {中华人民共和国国家市场监督管理总局 and 国家标准化管理委员会},
  title      = {GB/T35273-2020. 中华人民共和国国家标准-信息安全技术个人信息安全规范},
  address    = {北京},
  publisher  = {中国标准出版社},
  year       = {2020},
  key        = {zhong1 hua2 ren2 min2 gong4 he2 guo2},
}

@book{luyujie2018,
  author     = {{(日)斋藤康毅著} and {陆宇杰译}},
  title      = {深度学习入门：基于Python的理论与实践},
  address    = {北京},
  publisher  = {人民邮电出版社},
  year       = {2018},
  pages      = {230},
  key        = {lu4 yu3 jie2},
}

@book{luyujie_216,
  author     = {{(日)斋藤康毅著} and {陆宇杰译}},
  title      = {深度学习入门：基于Python的理论与实践},
  address    = {北京},
  publisher  = {人民邮电出版社},
  year       = {2018},
  pages      = {202-216},
  key        = {lu4 yu3 jie2},
}

@book{luyujie_215,
  author     = {{(日)斋藤康毅著} and {陆宇杰译}},
  title      = {深度学习入门：基于Python的理论与实践},
  address    = {北京},
  publisher  = {人民邮电出版社},
  year       = {2018},
  pages      = {215},
  key        = {lu4 yu3 jie2},
}

@book{luyujie_214,
  author     = {{(日)斋藤康毅著} and {陆宇杰译}},
  title      = {深度学习入门：基于Python的理论与实践},
  address    = {北京},
  publisher  = {人民邮电出版社},
  year       = {2018},
  pages      = {214},
  key        = {lu4 yu3 jie2},
}

@book{luyujie_206,
  author     = {{(日)斋藤康毅著} and {陆宇杰译}},
  title      = {深度学习入门：基于Python的理论与实践},
  address    = {北京},
  publisher  = {人民邮电出版社},
  year       = {2018},
  pages      = {206},
  key        = {lu4 yu3 jie2},
}

@book{luyujie_205,
  author     = {{(日)斋藤康毅著} and {陆宇杰译}},
  title      = {深度学习入门：基于Python的理论与实践},
  address    = {北京},
  publisher  = {人民邮电出版社},
  year       = {2018},
  pages      = {205},
  key        = {lu4 yu3 jie2},
}

@book{luyujie_204,
  author     = {{(日)斋藤康毅著} and {陆宇杰译}},
  title      = {深度学习入门：基于Python的理论与实践},
  address    = {北京},
  publisher  = {人民邮电出版社},
  year       = {2018},
  pages      = {204},
  key        = {lu4 yu3 jie2},
}

@book{luyujie_202,
  author     = {{(日)斋藤康毅著} and {陆宇杰译}},
  title      = {深度学习入门：基于Python的理论与实践},
  address    = {北京},
  publisher  = {人民邮电出版社},
  year       = {2018},
  pages      = {202},
  key        = {lu4 yu3 jie2},
}

@techreport{cifar10_2009,
  author     = {{Alex Krizhevsky}},
  title      = {Learning Multiple Layers of Features from Tiny Images},
  address    = {University of Toronto},
  publisher  = {University of Toronto},
  year       = {2009},
}

@InProceedings{He_2016_CVPR,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Deep Residual Learning for Image Recognition},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@online{yanjianweishi,
  author     = {{张小king}},
  title      = {眼见怎样为实？},
  year       = {2017},
  date       = {2017-10-08},
  urldate    = {2021-04-15},
  url        = {https://zhuanlan.zhihu.com/p/29853731},
  key        = {zhang1 xiao3 king},
}

@online{mubiaodingwei,
  author     = {{Meringue\_zz}},
  title      = {目标定位和检测系列（1）：一些基本概念},
  year       = {2018},
  date       = {2018-01-23},
  urldate    = {2021-04-15},
  url        = {https://blog.csdn.net/sinat_34474705/article/details/79131542},
  key        = {Meringue zz},
}

@InProceedings{10.1007/978-3-319-40159-1_19,
author="D'Amato, Anthony and Boussard, Matthieu",
editor="de la Prieta, Fernando
and Escalona, Mar{\'i}a J.
and Corchuelo, Rafael
and Mathieu, Philippe
and Vale, Zita
and Campbell, Andrew T.
and Rossi, Silvia
and Adam, Emmanuel
and Jim{\'e}nez-L{\'o}pez, Mar{\'i}a D.
and Navarro, Elena M.
and Moreno, Mar{\'i}a N.",
title="Forgetting Methods for White Box Learning",
booktitle="Trends in Practical Applications of Scalable Multi-Agent Systems, the PAAMS Collection",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="225--236",
abstract="In the Internet of Things (IoT) domain, being able to propose a contextualized and personalized user experience is a major issue. The explosion of connected objects makes it possible to gather more and more information about users and therefore create new, more innovative services that are truly adapted to users. To attain these goals, and meet the user expectations, applications must learn from user behavior and continuously adapt this learning accordingly. To achieve this, we propose a solution that provides a simple way to inject this kind of behavior into IoT applications by pairing a learning algorithm (C4.5) with Behavior Trees. In this context, this paper presents new forgetting methods for the C4.5 algorithm in order to continuously adapt the learning.",
isbn="978-3-319-40159-1"
}

@InProceedings{pmlr-v130-izzo21a,
  title = 	 { Approximate Data Deletion from Machine Learning Models },
  author =       {Izzo, Zachary and Anne Smart, Mary and Chaudhuri, Kamalika and Zou, James},
  booktitle = 	 {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2008--2016},
  year = 	 {2021},
  editor = 	 {Banerjee, Arindam and Fukumizu, Kenji},
  volume = 	 {130},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--15 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v130/izzo21a/izzo21a.pdf},
  url = 	 {http://proceedings.mlr.press/v130/izzo21a.html},
  abstract = 	 { Deleting data from a trained machine learning (ML) model is a critical task in many applications. For example, we may want to remove the influence of training points that might be out of date or outliers. Regulations such as EU’s General Data Protection Regulation also stipulate that individuals can request to have their data deleted. The naive approach to data deletion is to retrain the ML model on the remaining data, but this is too time consuming. In this work, we propose a new approximate deletion method for linear and logistic models whose computational cost is linear in the the feature dimension d and independent of the number of training data n. This is a significant gain over all existing methods, which all have superlinear time dependence on the dimension. We also develop a new feature-injection test to evaluate the thoroughness of data deletion from ML models. }
}

@InProceedings{pmlr-v119-wu20b, 
  title = {{D}elta{G}rad: Rapid retraining of machine learning models}, 
  author = {Wu, Yinjun and Dobriban, Edgar and Davidson, Susan}, 
  booktitle = {Proceedings of the 37th International Conference on Machine Learning}, 
  pages = {10355--10366},
  year = {2020}, 
  editor = {Hal Daumé III and Aarti Singh}, 
  volume = {119}, 
  series = {Proceedings of Machine Learning Research}, 
  month = {13--18 Jul}, 
  publisher = {PMLR}, 
  pdf = {http://proceedings.mlr.press/v119/wu20b/wu20b.pdf}, 
  url = { http://proceedings.mlr.press/v119/wu20b.html }, 
  abstract = {Machine learning models are not static and may need to be retrained on slightly changed datasets, for instance, with the addition or deletion of a set of data points. This has many applications, including privacy, robustness, bias reduction, and uncertainty quantifcation. However, it is expensive to retrain models from scratch. To address this problem, we propose the DeltaGrad algorithm for rapid retraining machine learning models based on information cached during the training phase. We provide both theoretical and empirical support for the effectiveness of DeltaGrad, and show that it compares favorably to the state of the art.} 
}

@InProceedings{pmlr-v132-neel21a, 
  title = {Descent-to-Delete: Gradient-Based Methods for Machine Unlearning}, 
  author = {Neel, Seth and Roth, Aaron and Sharifi-Malvajerdi, Saeed}, 
  booktitle = {Proceedings of the 32nd International Conference on Algorithmic Learning Theory}, 
  pages = {931--962}, 
  year = {2021}, 
  editor = {Vitaly Feldman and Katrina Ligett and Sivan Sabato},
  volume = {132}, 
  series = {Proceedings of Machine Learning Research}, 
  month = {16--19 Mar}, 
  publisher = {PMLR}, 
  pdf = {http://proceedings.mlr.press/v132/neel21a/neel21a.pdf}, 
  url = { http://proceedings.mlr.press/v132/neel21a.html }, 
  abstract = {We study the data deletion problem for convex models. By leveraging techniques from convex optimization and reservoir sampling, we give the first data deletion algorithms that are able to handle an arbitrarily long sequence of adversarial updates while promising both per-deletion run-time and steady-state error that do not grow with the length of the update sequence. We also introduce several new conceptual distinctions: for example, we can ask that after a deletion, the entire state maintained by the optimization algorithm is statistically indistinguishable from the state that would have resulted had we retrained, or we can ask for the weaker condition that only the observable output is statistically indistinguishable from the observable output that would have resulted from retraining. We are able to give more efficient deletion algorithms under this weaker deletion criterion.} 
}

@inproceedings{10.1145/3196494.3196517,
  author = {Cao, Yinzhi and Yu, Alexander Fangxiao and Aday, Andrew and Stahl, Eric and Merwine, Jon and Yang, Junfeng},
  title = {Efficient Repair of Polluted Machine Learning Systems via Causal Unlearning},
  year = {2018},
  isbn = {9781450355766},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3196494.3196517},
  doi = {10.1145/3196494.3196517},
  abstract = {Machine learning systems, though being successful in many real-world applications, are known to remain prone to errors and attacks. A major attack, called data pollution, injects maliciously crafted training data samples into the training set, causing the system to learn an incorrect model and subsequently misclassify testing samples. A natural solution to a data pollution attack is to remove the polluted data from the training set and relearn a clean model. Unfortunately, the training set of a real-world machine learning system can contain millions of samples; it is thus hopeless for an administrator to manually inspect all of them to weed out the polluted ones.This paper presents an approach called causal unlearning and a corresponding system called KARMA to efficiently repair a polluted learning system. KARMA dramatically reduces the manual effort of administrators by automatically detecting the set of polluted training data samples with high precision and recall. Evaluation on three learning systems show that KARMA greatly reduces manual effort for repair, and has high precision and recall.},
  booktitle = {Proceedings of the 2018 on Asia Conference on Computer and Communications Security},
  pages = {735–747},
  numpages = {13},
  keywords = {data pollution attacks, machine unlearning, causality},
  location = {Incheon, Republic of Korea},
  series = {ASIACCS '18}
}

@InProceedings{10.1007/978-3-030-58526-6_23,
  author="Golatkar, Aditya
  and Achille, Alessandro
  and Soatto, Stefano",
  editor="Vedaldi, Andrea
  and Bischof, Horst
  and Brox, Thomas
  and Frahm, Jan-Michael",
  title="Forgetting Outside the Box: Scrubbing Deep Networks of Information Accessible from Input-Output Observations",
  booktitle="Computer Vision -- ECCV 2020",
  year="2020",
  publisher="Springer International Publishing",
  address="Cham",
  pages="383--398",
  abstract="We describe a procedure for removing dependency on a cohort of training data from a trained deep network that improves upon and generalizes previous methods to different readout functions, and can be extended to ensure forgetting in the final activations of the network. We introduce a new bound on how much information can be extracted per query about the forgotten cohort from a black-box network for which only the input-output behavior is observed. The proposed forgetting procedure has a deterministic part derived from the differential equations of a linearized version of the model, and a stochastic part that ensures information destruction by adding noise tailored to the geometry of the loss landscape. We exploit the connections between the final activations and weight dynamics of a DNN inspired by Neural Tangent Kernels to compute the information in the final activations.",
  isbn="978-3-030-58526-6"
}

@inproceedings{10.1145/3319535.3363226,
  author = {Du, Min and Chen, Zhi and Liu, Chang and Oak, Rajvardhan and Song, Dawn},
  title = {Lifelong Anomaly Detection Through Unlearning},
  year = {2019},
  isbn = {9781450367479},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3319535.3363226},
  doi = {10.1145/3319535.3363226},
  abstract = {Anomaly detection is essential towards ensuring system security and reliability. Powered by constantly generated system data, deep learning has been found both effective and flexible to use, with its ability to extract patterns without much domain knowledge. Existing anomaly detection research focuses on a scenario referred to as zero-positive, which means that the detection model is only trained for normal (i.e., negative) data. In a real application scenario, there may be additional manually inspected positive data provided after the system is deployed. We refer to this scenario as lifelong anomaly detection. However, we find that existing approaches are not easy to adopt such new knowledge to improve system performance. In this work, we are the first to explore the lifelong anomaly detection problem, and propose novel approaches to handle corresponding challenges. In particular, we propose a framework called unlearning, which can effectively correct the model when a false negative (or a false positive) is labeled. To this aim, we develop several novel techniques to tackle two challenges referred to as exploding loss and catastrophic forgetting. In addition, we abstract a theoretical framework based on generative models. Under this framework, our unlearning approach can be presented in a generic way to be applied to most zero-positive deep learning-based anomaly detection algorithms to turn them into corresponding lifelong anomaly detection solutions. We evaluate our approach using two state-of-the-art zero-positive deep learning anomaly detection architectures and three real-world tasks. The results show that the proposed approach is able to significantly reduce the number of false positives and false negatives through unlearning.},
  booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
  pages = {1283–1297},
  numpages = {15},
  keywords = {unlearning, anomaly detection, online learning},
  location = {London, United Kingdom},
  series = {CCS '19}
}

@ARTICLE{2020arXiv200202730B,
       author = {{Baumhauer}, Thomas and {Sch{\"o}ttle}, Pascal and {Zeppelzauer}, Matthias},
        title = "{Machine Unlearning: Linear Filtration for Logit-based Classifiers}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2020,
        month = feb,
          eid = {arXiv:2002.02730},
        pages = {arXiv:2002.02730},
archivePrefix = {arXiv},
       eprint = {2002.02730},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv200202730B},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2020arXiv200304247S,
       author = {{Sommer}, David Marco and {Song}, Liwei and {Wagh}, Sameer and {Mittal}, Prateek},
        title = "{Towards Probabilistic Verification of Machine Unlearning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2020,
        month = mar,
          eid = {arXiv:2003.04247},
        pages = {arXiv:2003.04247},
archivePrefix = {arXiv},
       eprint = {2003.04247},
 primaryClass = {cs.CR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv200304247S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@InProceedings{pmlr-v119-guo20c, 
title = {Certified Data Removal from Machine Learning Models}, 
author = {Guo, Chuan and Goldstein, Tom and Hannun, Awni and Van Der Maaten, Laurens}, 
booktitle = {Proceedings of the 37th International Conference on Machine Learning}, 
pages = {3832--3842}, 
year = {2020}, 
editor = {Hal Daumé III and Aarti Singh}, 
volume = {119}, 
series = {Proceedings of Machine Learning Research}, 
month = {13--18 Jul}, 
publisher = {PMLR}, 
pdf = {http://proceedings.mlr.press/v119/guo20c/guo20c.pdf}, 
url = { http://proceedings.mlr.press/v119/guo20c.html },
abstract = {Good data stewardship requires removal of data at the request of the data’s owner. This raises the question if and how a trained machine-learning model, which implicitly stores information about its training data, should be affected by such a removal request. Is it possible to “remove” data from a machine-learning model? We study this problem by defining certified removal: a very strong theoretical guarantee that a model from which data is removed cannot be distinguished from a model that never observed the data to begin with. We develop a certified-removal mechanism for linear classifiers and empirically study learning settings in which this mechanism is practical.} 
}

@article{10.1145/293347.293351,
author = {Kearns, Michael},
title = {Efficient Noise-Tolerant Learning from Statistical Queries},
year = {1998},
issue_date = {Nov. 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {6},
issn = {0004-5411},
url = {https://doi.org/10.1145/293347.293351},
doi = {10.1145/293347.293351},
abstract = {In this paper, we study the problem of learning in the presence of classification noise in the probabilistic learning model of Valiant and its variants. In order to identify the class of “robust” learning algorithms in the most general way, we formalize a new but related model of learning from statistical queries. Intuitively, in this model a learning algorithm is forbidden to examine individual examples of the unknown target function, but is given acess to an oracle providing estimates of probabilities over the sample space of random examples.One of our main results shows that any class of functions learnable from statistical queries is in fact learnable with classification noise in Valiant's model, with a noise rate approaching the information-theoretic barrier of 1/2. We then demonstrate the generality of the statistical query model, showing that practically every class learnable in Valiant's model and its variants can also be learned in the new model (and thus can be learned in the presence of noise). A notable exception to this statement is the class of parity functions, which we prove is not learnable from statistical queries, and for which no noise-tolerant algorithm is known.},
journal = {J. ACM},
month = nov,
pages = {983–1006},
numpages = {24},
keywords = {computational learning theory, machine learning}
}

@InProceedings{pmlr-v70-koh17a, 
title = {Understanding Black-box Predictions via Influence Functions}, 
author = {Pang Wei Koh and Percy Liang}, 
booktitle = {Proceedings of the 34th International Conference on Machine Learning}, pages = {1885--1894},
year = {2017}, editor = {Precup, Doina and Teh, Yee Whye}, 
volume = {70}, series = {Proceedings of Machine Learning Research}, 
month = {06--11 Aug}, publisher = {PMLR}, 
pdf = {http://proceedings.mlr.press/v70/koh17a/koh17a.pdf}, 
url = { http://proceedings.mlr.press/v70/koh17a.html }, 
abstract = {How can we explain the predictions of a black-box model? In this paper, we use influence functions — a classic technique from robust statistics — to trace a model’s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.} 
}

@book{cook_weisberg_1982,
  author     = {Cook, R. Dennis and Weisberg, Sanford},
  title      = {Residuals and Influence in Regression},
  address    = {New York},
  publisher  = {Chapman and Hall},
  year       = {1982},
  pages      = {112},
  key        = {cook weisberg},
}

@inproceedings{10.5555/2671225.2671227,
author = {Fredrikson, Matthew and Lantz, Eric and Jha, Somesh and Lin, Simon and Page, David and Ristenpart, Thomas},
title = {Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing},
year = {2014},
isbn = {9781931971157},
publisher = {USENIX Association},
address = {USA},
abstract = {We initiate the study of privacy in pharmacogenetics, wherein machine learning models are used to guide medical treatments based on a patient's genotype and background. Performing an in-depth case study on privacy in personalized warfarin dosing, we show that suggested models carry privacy risks, in particular because attackers can perform what we call model inversion: an attacker, given the model and some demographic information about a patient, can predict the patient's genetic markers.As differential privacy (DP) is an oft-proposed solution for medical settings such as this, we evaluate its effectiveness for building private versions of pharmacogenetic models. We show that DP mechanisms prevent our model inversion attacks when the privacy budget is carefully selected. We go on to analyze the impact on utility by performing simulated clinical trials with DP dosing models. We find that for privacy budgets effective at preventing attacks, patients would be exposed to increased risk of stroke, bleeding events, and mortality. We conclude that current DP mechanisms do not simultaneously improve genomic privacy while retaining desirable clinical efficacy, highlighting the need for new mechanisms that should be evaluated in situ using the general methodology introduced by our work.},
booktitle = {Proceedings of the 23rd USENIX Conference on Security Symposium},
pages = {17–32},
numpages = {16},
location = {San Diego, CA},
series = {SEC'14}
}

@inproceedings{10.1145/2810103.2813677,
author = {Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
title = {Model Inversion Attacks That Exploit Confidence Information and Basic Countermeasures},
year = {2015},
isbn = {9781450338325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2810103.2813677},
doi = {10.1145/2810103.2813677},
abstract = {Machine-learning (ML) algorithms are increasingly utilized in privacy-sensitive applications such as predicting lifestyle choices, making medical diagnoses, and facial recognition. In a model inversion attack, recently introduced in a case study of linear classifiers in personalized medicine by Fredrikson et al., adversarial access to an ML model is abused to learn sensitive genomic information about individuals. Whether model inversion attacks apply to settings outside theirs, however, is unknown. We develop a new class of model inversion attack that exploits confidence values revealed along with predictions. Our new attacks are applicable in a variety of settings, and we explore two in depth: decision trees for lifestyle surveys as used on machine-learning-as-a-service systems and neural networks for facial recognition. In both cases confidence values are revealed to those with the ability to make prediction queries to models. We experimentally show attacks that are able to estimate whether a respondent in a lifestyle survey admitted to cheating on their significant other and, in the other context, show how to recover recognizable images of people's faces given only their name and access to the ML model. We also initiate experimental exploration of natural countermeasures, investigating a privacy-aware decision tree training algorithm that is a simple variant of CART learning, as well as revealing only rounded confidence values. The lesson that emerges is that one can avoid these kinds of MI attacks with negligible degradation to utility.},
booktitle = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
pages = {1322–1333},
numpages = {12},
keywords = {machine learning, attacks, privacy},
location = {Denver, Colorado, USA},
series = {CCS '15}
}

@inproceedings{10.5555/3241094.3241142,
author = {Tram\`{e}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K. and Ristenpart, Thomas},
title = {Stealing Machine Learning Models via Prediction APIs},
year = {2016},
isbn = {9781931971324},
publisher = {USENIX Association},
address = {USA},
abstract = {Machine learning (ML) models may be deemed confidential due to their sensitive training data, commercial value, or use in security applications. Increasingly often, confidential ML models are being deployed with publicly accessible query interfaces. ML-as-a-service ("predictive analytics") systems are an example: Some allow users to train models on potentially sensitive data and charge others for access on a pay-per-query basis.The tension between model confidentiality and public access motivates our investigation of model extraction attacks. In such attacks, an adversary with black-box access, but no prior knowledge of an ML model's parameters or training data, aims to duplicate the functionality of (i.e., "steal") the model. Unlike in classical learning theory settings, ML-as-a-service offerings may accept partial feature vectors as inputs and include confidence values with predictions. Given these practices, we show simple, efficient attacks that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, neural networks, and decision trees. We demonstrate these attacks against the online services of BigML and Amazon Machine Learning. We further show that the natural countermeasure of omitting confidence values from model outputs still admits potentially harmful model extraction attacks. Our results highlight the need for careful ML model deployment and new model extraction countermeasures.},
booktitle = {Proceedings of the 25th USENIX Conference on Security Symposium},
pages = {601–618},
numpages = {18},
location = {Austin, TX, USA},
series = {SEC'16}
}

@INPROCEEDINGS{7958568,
  author={R. {Shokri} and M. {Stronati} and C. {Song} and V. {Shmatikov}},
  booktitle={2017 IEEE Symposium on Security and Privacy (SP)}, 
  title={Membership Inference Attacks Against Machine Learning Models}, 
  year={2017},
  volume={},
  number={},
  pages={3-18},
  doi={10.1109/SP.2017.41}
  }

  @ARTICLE{8634878,
  author={S. {Truex} and L. {Liu} and M. E. {Gursoy} and L. {Yu} and W. {Wei}},
  journal={IEEE Transactions on Services Computing}, 
  title={Demystifying Membership Inference Attacks in Machine Learning as a Service}, 
  year={2019},
  volume={},
  number={},
  pages={1-1},
  doi={10.1109/TSC.2019.2897554}}

@inproceedings{10.1145/3243734.3243855,
author = {Nasr, Milad and Shokri, Reza and Houmansadr, Amir},
title = {Machine Learning with Membership Privacy Using Adversarial Regularization},
year = {2018},
isbn = {9781450356930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243734.3243855},
doi = {10.1145/3243734.3243855},
abstract = {Machine learning models leak significant amount of information about their training sets, through their predictions. This is a serious privacy concern for the users of machine learning as a service. To address this concern, in this paper, we focus on mitigating the risks of black-box inference attacks against machine learning models. We introduce a mechanism to train models with membership privacy, which ensures indistinguishability between the predictions of a model on its training data and other data points (from the same distribution). This requires minimizing the accuracy of the best black-box membership inference attack against the model. We formalize this as a min-max game, and design an adversarial training algorithm that minimizes the prediction loss of the model as well as the maximum gain of the inference attacks. This strategy, which can guarantee membership privacy (as prediction indistinguishability), acts also as a strong regularizer and helps generalizing the model. We evaluate the practical feasibility of our privacy mechanism on training deep neural networks using benchmark datasets. We show that the min-max strategy can mitigate the risks of membership inference attacks (near random guess), and can achieve this with a negligible drop in the model's prediction accuracy (less than 4%).},
booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
pages = {634–646},
numpages = {13},
keywords = {data privacy, adversarial process, membership privacy, min-max game, machine learning, inference attacks, indistinguishability},
location = {Toronto, Canada},
series = {CCS '18}
}

@ARTICLE{2018arXiv180601246S,
       author = {{Salem}, Ahmed and {Zhang}, Yang and {Humbert}, Mathias and {Berrang}, Pascal and {Fritz}, Mario and {Backes}, Michael},
        title = "{ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Cryptography and Security, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
         year = 2018,
        month = jun,
          eid = {arXiv:1806.01246},
        pages = {arXiv:1806.01246},
archivePrefix = {arXiv},
       eprint = {1806.01246},
 primaryClass = {cs.CR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180601246S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{visser2017,
  author={Visser, M},
  journal={The Learning Organization}, 
  title={Learning and unlearning: a conceptual note}, 
  year={2017},
  volume={24},
  number={1},
  pages={49-57},
  doi={10.1108/TLO-10-2016-0070}
}

@ARTICLE{jishouling2021,
  author={纪守领 and 杜天宇 and 李进锋 and others},
  journal={软件学报}, 
  title={机器学习模型安全与隐私研究综述}, 
  year={2021},
  volume={32},
  number={1},
  pages={41-67},
  doi={10.13328/j.cnki.jos.006131},
}

@InProceedings{10.1007/978-3-030-21752-5_4,
author="Gutmann, Andreas
and Warner, Mark",
editor="Naldi, Maurizio
and Italiano, Giuseppe F.
and Rannenberg, Kai
and Medina, Manel
and Bourka, Athena",
title="Fight to Be Forgotten: Exploring the Efficacy of Data Erasure in Popular Operating Systems",
booktitle="Privacy Technologies and Policy",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="45--58",
abstract="A long history of longitudinal and intercultural research has identified decommissioned storage devices (e.g., USB memory sticks) as a serious privacy and security threat. Sensitive data deleted by previous owners have repeatedly been found on second-hand USB sticks through forensic analysis. Such data breaches are unlikely to occur when data is securely erased, rather than being deleted. Yet, research shows people confusing these two terms. In this paper, we report on an investigation of possible causes for this confusion. We analysed the user interface of two popular operating systems and found: (1) inconsistencies in the language used around delete and erase functions, (2) insecure default options, and (3) unclear or incomprehensible information around delete and erase functions. We discuss how this could result in data controllers becoming non-compliant with a legal obligation for erasure, putting data subjects at risk of accidental data breaches from the decommissioning of storage devices. Finally, we propose improvements to the design of relevant user interface elements and the development of official guidelines for best practice on GDPR compatible data erasure procedures.",
isbn="978-3-030-21752-5"
}

@inproceedings{Kwak2017LetMU,
  title={Let Machines Unlearn - Machine Unlearning and the Right to be Forgotten},
  author={Chanhee Kwak and Junyeong Lee and Kyuhong Park and H. Lee},
  booktitle={AMCIS},
  year={2017}
}

@online{Francesco2018,
  author     = {Francesco, Corea},
  title      = {Machine Learning: what you are too afraid to ask},
  year       = {2018},
  date       = {2018-03-06},
  urldate    = {2021-04-15},
  url        = {https://datascience.foundation/sciencewhitepaper/machine-learning-what-you-are-too-afraid-to-ask},
}

@online{marketsmarkets2019,
  author     = {MarketsandMarkets},
  title      = {Facial Recognition Market by Component},
  year       = {2019},
  date       = {2019-10-09},
  urldate    = {2021-04-15},
  url        = {https://www.marketsandmarkets.com/Market-Reports/facial-recognition-market-995.html},
}

@article{VILLARONGA2018304,
title = {Humans forget, machines remember: Artificial intelligence and the Right to Be Forgotten},
journal = {Computer Law and Security Review},
volume = {34},
number = {2},
pages = {304-313},
year = {2018},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2017.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0267364917302091},
author = {Eduard Fosch Villaronga and Peter Kieseberg and Tiffany Li},
keywords = {Right to Be Forgotten, Artificial intelligence (AI), Privacy, Data deletion, Memory},
abstract = {This article examines the problem of AI memory and the Right to Be Forgotten. First, this article analyzes the legal background behind the Right to Be Forgotten, in order to understand its potential applicability to AI, including a discussion on the antagonism between the values of privacy and transparency under current E.U. privacy law. Next, the authors explore whether the Right to Be Forgotten is practicable or beneficial in an AI/machine learning context, in order to understand whether and how the law should address the Right to Be Forgotten in a post-AI world. The authors discuss the technical problems faced when adhering to strict interpretation of data deletion requirements under the Right to Be Forgotten, ultimately concluding that it may be impossible to fulfill the legal aims of the Right to Be Forgotten in artificial intelligence environments. Finally, this article addresses the core issue at the heart of the AI and Right to Be Forgotten problem: the unfortunate dearth of interdisciplinary scholarship supporting privacy law and regulation.},
}

@inproceedings{sarkar:hal-01824058,
  TITLE = {{Towards Enforcement of the EU GDPR: Enabling Data Erasure}},
  AUTHOR = {Sarkar, Subhadeep and Ban{\^a}tre, Jean-Pierre and Rilling, Louis and Morin, Christine},
  URL = {https://hal.inria.fr/hal-01824058},
  BOOKTITLE = {{iThings 2018 - 11th IEEE International Conference of Internet of Things}},
  ADDRESS = {Halifax, Canada},
  PAGES = {1-8},
  YEAR = {2018},
  MONTH = Jul,
  KEYWORDS = {Personal data privacy ; EU GDPR ; Internet of Things (IoT) ; Data erasure},
  PDF = {https://hal.inria.fr/hal-01824058/file/position_paper.pdf},
  HAL_ID = {hal-01824058},
  HAL_VERSION = {v1},
}

@online{caipeiru2019,
  author     = {蔡培如},
  title      = {被遗忘权制度的反思与再建构},
  year       = {2019},
  date       = {2019-10-09},
  urldate    = {2021-04-15},
  url        = {http://www.calaw.cn/article/default.asp?id=13355},
}

@article{GUO2019102805,
title = {A survey on deep learning based face recognition},
journal = {Computer Vision and Image Understanding},
volume = {189},
pages = {102805},
year = {2019},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2019.102805},
url = {https://www.sciencedirect.com/science/article/pii/S1077314219301183},
author = {Guodong Guo and Na Zhang},
keywords = {Deep learning, Face recognition, Artificial Neural Network, Convolutional Neural Networks, Autoencoder, Generative Adversarial Networks},
abstract = {Deep learning, in particular the deep convolutional neural networks, has received increasing interests in face recognition recently, and a number of deep learning methods have been proposed. This paper summarizes about 330 contributions in this area. It reviews major deep learning concepts pertinent to face image analysis and face recognition, and provides a concise overview of studies on specific face recognition problems, such as handling variations in pose, age, illumination, expression, and heterogeneous face matching. A summary of databases used for deep face recognition is given as well. Finally, some open challenges and directions are discussed for future research.}
}

@inproceedings{deepface2014,
author = {Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
year = {2014},
month = {09},
pages = {},
title = {DeepFace: Closing the Gap to Human-Level Performance in Face Verification},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2014.220}
}























@article{zhangkun1994,
  author     = {张昆 and 冯立群 and 余昌钰 and others},
  title      = {机器人柔性手腕的球面齿轮设计研究},
  journal    = {清华大学学报: 自然科学版},
  volume     = {34},
  number     = {2},
  pages      = {1--7},
  year       = {1994},
  key        = {zhang1 kun1},
}

@book{zhukezhen1973,
  author     = {竺可桢},
  title      = {物理学论},
  address    = {北京},
  publisher  = {科学出版社},
  year       = {1973},
  pages      = {56--60},
  key        = {zhu2 ke3 zhen1},
}

@inproceedings{dupont1974bone,
  author     = {Dupont, B},
  title      = {Bone marrow transplantation in severe combined immunodeficiency with an unrelated MLC compatible donor},
  editor     = {White, H J and Smith, R},
  booktitle  = {Proceedings of the third annual meeting of the International Society for Experimental Hematology},
  address    = {Houston},
  publisher  = {International Society for Experimental Hematology},
  year       = {1974},
  pages      = {44--46},
}

@mastersthesis{zhengkaiqing1987,
  author     = {郑开青},
  title      = {通讯系统模拟及软件},
  address    = {北京},
  school     = {清华大学无线电系},
  year       = {1987},
  key        = {zheng4 kai1 qing1},
}

@patent{jiangxizhou1980,
  author     = {姜锡洲},
  title      = {一种温热外敷药制备方案: 中国, 88105607.3},
  date       = {1980-07-26},
  key        = {jiang1 xi1 zhou1},
}

@standard{jianduju1994,
  author     = {中华人民共和国国家技术监督局},
  title      = {GB3100-3102. 中华人民共和国国家标准-量与单位},
  address    = {北京},
  publisher  = {中国标准出版社},
  year       = {1994},
  key        = {zhong1 hua2 ren2 min2 gong4 he2 guo2},
}

@article{merkt1995rotational,
  author     = {Merkt, Fr{\'e}d{\'e}ric and Mackenzie, S R and Softley, Timothy P},
  title      = {Rotational Autoionization Dynamics in High Rydberg States of Nitrogen},
  journal    = {J Chem Phys},
  year       = {1995},
  volume     = {103},
  pages      = {4509--4518},
}

@article{mellinger1996laser,
  author     = {Mellinger, A and Vidal, C R and Jungen, {Ch}},
  title      = {Laser reduced fluorescence study of the carbon monoxide nd triplet Rydberg series - Experimental results and multichannel quantum defect analysis},
  journal    = {J Chem Phys},
  year       = {1996},
  volume     = {104},
  pages      = {8913--8921},
}

@article{bixon1996dynamics,
  author     = {Bixon, M and Jortner, Joshua},
  title      = {The dynamics of predissociating high {Rydberg} states of {NO}},
  journal    = {J Chem Phys},
  year       = {1996},
  volume     = {105},
  pages      = {1363--1382},
}

@article{mahui1995,
  author     = {马辉 and 李俭 and 刘耀明 and others},
  title      = {利用 {REMPI} 方法测量 {BaF} 高里德堡系列光谱},
  journal    = {化学物理学报},
  year       = {1995},
  volume     = {8},
  pages      = {308--311},
  key        = {ma3 hui1},
}

@article{carlson1981two,
  author     = {Carlson, N W and Taylor, A J and Jones, K M and Schawlow, A L},
  title      = {Two-step polarization-labeling spectroscopy of excited states of {Na2}},
  journal    = {Phys Rev A},
  year       = {1981},
  volume     = {24},
  pages      = {822--834},
}

@article{taylor1983scanning,
  author     = {Taylor, A J and Jones, K M and Schawlow, A L},
  title      = {Scanning pulsed-polarization spectrometer applied to {Na2}},
  journal    = {J Opt Soc Am},
  year       = {1983},
  volume     = {73},
  pages      = {994--998},
}

@article{taylor1981study,
  author     = {Taylor, A J and Jones, K M and Schawlow, A L},
  title      = {A study of the excited {1$\Sigma$g+} states in {Na2}},
  journal    = {Opt Commun},
  year       = {1981},
  volume     = {39},
  pages      = {47--50},
}

@article{shimizu1983laser,
  author     = {Shimizu, Kazuko and Shimizu, Fujio},
  title      = {Laser induced fluorescence spectra of the a {3$\Pi$u--X 1$\Sigma$g+} band of {Na2} by molecular beam},
  journal    = {J Chem Phys},
  year       = {1983},
  volume     = {78},
  pages      = {1126--1131},
}

@article{atkinson1982experimental,
  author     = {Atkinson, J B and Becker, J and Demtr{\"o}der, W},
  title      = {Experimental observation of the a {3$\Pi$u} state of {Na2}},
  journal    = {Chem Phys Lett},
  year       = {1982},
  volume     = {87},
  pages      = {92--97},
}

@article{kusch1975perturbations,
  author     = {Kusch, P and Hessel, M M},
  title      = {Perturbations in the A {1$\Sigma$u+} state of {Na2}},
  journal    = {J Chem Phys},
  year       = {1975},
  volume     = {63},
  pages      = {4087--4088},
}

@book{guangxi1993,
  author     = {广西壮族自治区林业厅},
  title      = {广西自然保护区},
  address    = {北京},
  publisher  = {中国林业出版社},
  year       = {1993},
  key        = {guang3 xi1 zhuang4 zu2 zi4 zhi4 qu1},
}

@book{huosini1989guwu,
  author     = {霍斯尼},
  title      = {谷物科学与工艺学原理},
  translator = {李庆龙},
  edition    = {2},
  address    = {北京},
  publisher  = {中国食品出版社},
  year       = {1989},
  pages      = {15--20},
  key        = {huo4 si1 ni2},
}

@book{wangfuzhi1865songlun,
  author     = {王夫之},
  title      = {宋论},
  edition    = {刻本},
  address    = {金陵},
  publisher  = {曾氏},
  year       = {1865（清同治四年）},
  key        = {wang2 fu1 zhi1},
}

@book{zhaoyaodong1998xinshidai,
  author     = {赵耀东},
  title      = {新时代的工业工程师},
  address    = {台北},
  publisher  = {天下文化出版社},
  year       = {1998},
  urldate    = {1998-09-26},
  url        = {http://www.ie.nthu.edu.tw/info/ie.newie.htm},
  key        = {zhao4 yao4 dong1},
}

@standard{biaozhunhua2002tushu,
  author     = {全国信息与文献工作标准化技术委员会出版物格式分委员会},
  title      = {GB/T 12450-2001 图书书名页},
  address    = {北京},
  publisher  = {中国标准出版社},
  year       = {2002},
  pages      = {1},
  key        = {quan2 guo2 xin4 xi1},
}

@book{chubanzhuanye2004,
  author     = {全国出版专业职业资格考试办公室},
  title      = {全国出版专业职业资格考试辅导教材: 出版专业理论与实务•中级},
  edition    = {2014},
  address    = {上海},
  publisher  = {上海辞书出版社},
  year       = {2004},
  pages      = {299--307},
  key        = {quan2 guo2 chu1 ban3 ye4},
}

@techreport{who1970factors,
  author     = {{World Health Organization}},
  title      = {Factors Regulating the Immune Response: Report of {WHO Scientific Group}},
  address    = {Geneva},
  publisher  = {WHO},
  year       = {1970},
}

@book{peebles2001probability,
  author     = {Peebles, Jr, Peyton Z.},
  title      = {Probability, Random Variables, and Random Signal Principles},
  edition    = {4},
  address    = {New York},
  publisher  = {McGraw Hill},
  year       = {2001},
}

@incollection{baishunong1998zhiwu,
  author     = {白书农},
  title      = {植物开花研究},
  editor     = {李承森},
  booktitle  = {植物科学进展},
  address    = {北京},
  publisher  = {高等教育出版社},
  year       = {1998},
  pages      = {146--163},
  key        = {bai2 shu1 nong2},
}

@incollection{weinstein1974pathogenic,
  author     = {Weinstein, L and Swertz, M N},
  title      = {Pathogenic Properties of Invading Microorganism},
  editor     = {Sodeman, Jr, William A and Sodeman, William A},
  booktitle  = {Pathologic physiology: mechanisms of disease},
  address    = {Philadelphia},
  publisher  = {Saunders},
  year       = {1974},
  pages      = {745--772},
}

@inproceedings{hanjiren1985lun,
  author     = {韩吉人},
  title      = {论职工教育的特点},
  editor     = {中国职工教育研究会},
  booktitle  = {职工教育研究论文集},
  address    = {北京},
  publisher  = {人民教育出版社},
  year       = {1985},
  pages      = {90--99},
  key        = {han2 ji2 ren2},
}

@periodical{dizhi1936dizhi,
  author     = {中国地质学会},
  title      = {地质评论},
  year       = {1936},
  volume     = {1},
  number     = {1},
  address    = {北京},
  publisher  = {地质出版社},
  key        = {zhong1 guo2 di4 zhi3 xue2 hui4},
}

@periodical{tushuguan1957tushuguanxue,
  author     = {中国图书馆学会},
  title      = {图书馆学通讯},
  year       = {1957/1990},
  number     = {1--4},
  address    = {北京},
  publisher  = {北京图书馆},
  key        = {zhong1 guo2 tu2 shu1 guan3 xue2 hui4},
}

@periodical{aaas1883science,
  author     = {{American Association for the Advancement of Science}},
  title      = {Science},
  year       = {1883},
  volume     = {1},
  number     = {1},
  address    = {Washington, D.C.},
  publisher  = {American Association for the Advancement of Science},
}

@newspaper{fugang2000fengsha,
  author     = {傅刚 and 赵承 and 李佳路},
  title      = {大风沙过后的思考},
  journal    = {北京青年报},
  date       = {2000-04-12},
  number     = {14},
  urldate    = {2002-03-06},
  url        = {http://www.bjyouth.com.cn/Bqb/20000412/B/4216%5ED0412B1401.htm},
  key        = {fu4 gang1},
}

@online{xiaoyu2001chubanye,
  author     = {萧钰},
  title      = {出版业信息化迈入快车道},
  year       = {2001},
  date       = {2001-12-19},
  urldate    = {2002-04-15},
  url        = {http://www.creader.com/news/20011219/200112190019.htm},
  key        = {xiao1 yu4},
}

@online{oclc2000about,
  author     = {{Online Computer Library Center, Inc}},
  title      = {About {OCLC}: History of Cooperation},
  year       = {2000},
  urldate    = {2000-01-08},
  url        = {http://www.oclc.org/about/cooperation.en.htm},
}

@software{scitor2000project,
  author     = {{Scitor Corporation}},
  title      = {Project scheduler},
  address    = {Sunnyvale, Calif.},
  publisher  = {Scitor Corporation},
  year       = {1983},
  medium     = {DK},
}
