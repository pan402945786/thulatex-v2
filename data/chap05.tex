% !TeX root = ../thuthesis-example.tex

\chapter{总结与展望}

\section{研究工作总结}

本文通过理论假设和实验验证的方法针对卷积神经网络如何遗忘的问题进行了系统研究。
第一章引言中首先介绍了遗忘问题产生的背景与研究的意义。随着以人脸识别为代表的人工智能技术的广泛应用，越来越多的隐私问题逐渐浮出水面。
研究者发现仅仅通过神经网络的输出数据就能对神经网络模型的输入数据进行还原，或者对神经网络模型训练出来的参数进行抽取，或者能判断出某个输入是否曾经被用于训练该模型。
这些攻击手段的出现给我们发出的一个明显信号就是神经网络模型中包含重要的信息，很可能会由于通过对机器学习模型的攻击而泄露个人隐私数据。这是数据遗忘的用户需求。
从法律角度上看，无论是欧盟出台的GDPR还是美国加州颁布的CCPA，从法律层面上规定了用户拥有“被遗忘权”。当用户需要删除数据时，数据管理者应当及时地履行约定。这是数据需要遗忘的法律要求。
面对这些现实需求，我们研究卷积神经网络的遗忘具有重要的现实意义。
然后，我们介绍了本文设计遗忘方法的主要贡献和本文的文章架构。

在第二章中，本文主要介绍了关于共享网络参数的人工神经网络相关工作和关于机器学习模型遗忘方法的相关工作。
迁移学习的思想和本文的思路在某种程度上是契合的，目的都是无需重新训练整个模型就能够快速地实现模型知识的迁移。
增量学习技术的出发点是克服神经网络本身固有灾难性遗忘。随着新的训练数据继续在网络中训练，原先已经训练过的类别在准确率上有不同程度的降低。
为了解决这个问题，研究人员尝试了多种在无需重新训练全部模型的情况下，想办法将新的类别加入到原有的网络模型当中的方法。其中一类方法就是共享网络参数的方法。
这种方法虽然有网络规模不断扩大的缺点，但是其共享网络参数的思想对本文具有借鉴意义。
在遗忘学习的研究方面，可以大致分为两个类别，一个是基于非神经网络的遗忘方法，这类方法虽然有时可以取得很好的效果，但是面对神经网络时却不能适用。
另一个基于神经网络的遗忘方法。研究者使用了各种方法来尝试还原网络参数，有的通过在权重上增加噪音，有的通过牛顿更新的方法去更新权重。但目前在卷积神经网络的遗忘方面尚没有一套成熟的解决方案。

第三章是本文的核心章节，在第三章为了让读者更好地理解卷积神经网络的分层抽象特性，我们首先介绍了卷积神经网络基本结构和原理。接着介绍了生物视觉信息处理的特点。
然后介绍了卷积神经网络的分层抽象特性。从这个特性出发我们设计了一套遗忘方法，方法可以分为三个步骤：首先确定分层的数值，然后重置并冻结参数，最后使用保留训练集进行训练，直至模型收敛。
我们为了测试遗忘的效果，选取了三个不同方面的测试指标，分别是测试准确率，收敛时间和激活距离。

第四章是对第三章遗忘方法的实验验证。我们设计了四个实验来进行验证，分别是确定冻结层数实验，冻结必要性验证实验，反向冻结验证实验和遗忘可持续性验证实验。确定冻结层数实验，目的是确定冻结参数的层次。
实验结果表明，对于ResNet18的网络结构来说，重置倒数6个层次的参数是个很好的选择。
冻结必要性实验的目的是验证对网络进行冻结的必要性。实验中设计了一套对比实验，通过三个指标的对比表明，冻结参数对提高遗忘效果是有必要的。
反向冻结实验作为本文遗忘方法的一个对照实验，同时也用来验证分层抽象特性的有效性。从实验结果来看，分层抽象特性的效果是明显的。
最后一个实验是遗忘可持续性验证实验，这个实验旨在探究本文提到的遗忘方法是否能够用来连续进行遗忘操作。最终实验结果表明，无论需要遗忘多少类别，本方法均可以达到理想的遗忘效果。

\section{存在问题与展望}
在机器学习模型会泄露个人隐私的背景下，本文对卷积神经网络模型的遗忘方法进行了研究。本文虽然在一定的范围内取得了很好的效果，但是仍有以下几点不足。

第一，本文只能适用于卷积神经网络。通用的机器学习遗忘方法还有待进一步探索和研究。

第二，本方法只能针对保留数据集的情况下使用。有一些实际情况是训练数据不是实时可用，这就导致重置网络参数后无法恢复保留类别原有的准确率。如何不用保留数据集就能实现很好的遗忘效果是一个值得后续研究的方向。

第三，本方法只适用于遗忘整个类别的情况，对于遗忘单个数据的操作，本方法不能做到很好地支持。作者认为有一些数据一旦被用于学习以后，其影响是无法消除的，因此无法被遗忘，有一些相关工作\cite{2018arXiv181205159T}的结论也支持这一点。

\section{本章小结}
本章对全文进行了概括性的总结并对本文目前尚未做到的工作进行了说明，同时又进行了一定的展望。随着卷积神经网络的普遍应用，用户隐私越来越受到重视，基于卷积神经网络的遗忘方法的相关研究势在必行。